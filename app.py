import streamlit as st
import cv2
import numpy as np
from PIL import Image
import plotly.express as px
from streamlit_drawable_canvas import st_canvas

# ==========================================
# 0. å…¨å±€é…ç½®
# ==========================================
st.set_page_config(page_title="Click on Image", layout="wide")

# ==========================================
# 1. æ ¸å¿ƒç®—æ³•ï¼šå¤šç‚¹å¹³å‡æ¨¡æ¿åŒ¹é…
# ==========================================
def run_multi_point_matching(img_gray, points, params):
    h, w = img_gray.shape
    radius = params['radius']
    window_size = radius * 2
    
    collected_patches = []
    
    # æå–ç‚¹å‡»ç‚¹å‘¨å›´çš„å›¾åƒå—
    for pt in points:
        x, y = int(pt[0]), int(pt[1])
        y1, y2 = max(0, y - radius), min(h, y + radius)
        x1, x2 = max(0, x - radius), min(w, x + radius)
        patch = img_gray[y1:y2, x1:x2]
        
        if patch.shape == (window_size, window_size):
            collected_patches.append(patch)
            
    if not collected_patches:
        return [], img_gray, np.zeros((10,10)), "æ— æ³•æå–æœ‰æ•ˆæ¨¡æ¿ï¼Œè¯·å‹¿ç‚¹å‡»è¾¹ç¼˜ã€‚"

    # è®¡ç®—å¹³å‡æ¨¡æ¿
    avg_template = np.mean(collected_patches, axis=0).astype(np.uint8)
    
    # é¢„å¤„ç†
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    img_enhanced = clahe.apply(img_gray)
    template_enhanced = clahe.apply(avg_template)

    # åŒ¹é…
    res = cv2.matchTemplate(img_enhanced, template_enhanced, cv2.TM_CCOEFF_NORMED)
    
    # ç­›é€‰
    loc = np.where(res >= params['threshold'])
    boxes = []
    for pt in zip(*loc[::-1]):
        boxes.append([int(pt[0]), int(pt[1]), window_size, window_size])
        
    rects, _ = cv2.groupRectangles(boxes, groupThreshold=1, eps=0.3)
    
    # ç»˜å›¾
    res_img = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)
    final_buds = []
    
    for (x, y, wb, hb) in rects:
        cv2.rectangle(res_img, (x, y), (x + wb, y + hb), (0, 0, 255), 2)
        final_buds.append([x, y])

    for pt in points:
        cv2.circle(res_img, (int(pt[0]), int(pt[1])), 4, (0, 255, 0), -1)

    return final_buds, res_img, avg_template, ""

# ==========================================
# 2. UI å¸ƒå±€
# ==========================================
st.title("ğŸ‘† ç›´æ¥ç‚¹å‡»ç‰ˆ (Click on Image)")
st.caption("ç°åœ¨å›¾ç‰‡ä¼šè‡ªåŠ¨é“ºæ»¡åŒºåŸŸï¼Œæ²¡æœ‰ç™½è‰²èƒŒæ™¯äº†ã€‚")

# ä¾§è¾¹æ å‚æ•°
st.sidebar.header("ğŸ›ï¸ å‚æ•°")
# æ³¨æ„ï¼šå› ä¸ºå›¾ç‰‡å¯èƒ½è¢«ç¼©æ”¾æ˜¾ç¤ºï¼Œè¿™é‡Œçš„åŠå¾„éœ€è¦æ ¹æ®è§†è§‰å¤§å°æ¥è°ƒï¼Œé»˜è®¤ç»™å°ä¸€ç‚¹
radius = st.sidebar.slider("æ ·æœ¬åŠå¾„ (Radius)", 10, 50, 20)
threshold = st.sidebar.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.3, 0.95, 0.60)

uploaded_file = st.file_uploader("ä¸Šä¼ å›¾åƒ", type=["jpg", "png", "tif"])

if uploaded_file:
    # 1. åŠ è½½åŸå§‹å›¾ç‰‡
    pil_img = Image.open(uploaded_file).convert("RGB")
    orig_w, orig_h = pil_img.size
    
    # 2. å…³é”®æ­¥éª¤ï¼šè®¡ç®—é€‚åº”å±å¹•çš„æ˜¾ç¤ºå°ºå¯¸
    # ä¸ºäº†é˜²æ­¢å›¾ç‰‡å¤ªå¤§æ’‘ç ´å±å¹•ï¼Œæˆ–è€…å¤ªå°ç•™ç™½ï¼Œæˆ‘ä»¬å°†å®½åº¦å›ºå®šä¸ºé€‚å®œå¤§å°ï¼ˆå¦‚ 700pxï¼‰
    # å¹¶ä¿æŒé•¿å®½æ¯”ç¼©æ”¾
    display_width = 700
    ratio = display_width / orig_w
    display_height = int(orig_h * ratio)
    
    # ç¼©æ”¾å›¾ç‰‡ç”¨äº Canvas æ˜¾ç¤ºå’Œå¤„ç† (è¿™æ ·é€Ÿåº¦ä¹Ÿæ›´å¿«)
    pil_img_resized = pil_img.resize((display_width, display_height), Image.Resampling.LANCZOS)
    img_array = np.array(pil_img_resized)
    img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)

    col1, col2 = st.columns([1.5, 1])

    with col1:
        st.subheader("1. ç‚¹å‡»æ ·æœ¬")
        
        # 3. Canvas è®¾ç½®ï¼šå®½é«˜å®Œå…¨ç­‰äºç¼©æ”¾åçš„å›¾ç‰‡å®½é«˜
        # è¿™æ ·å°±æ²¡æœ‰ç™½è‰²èƒŒæ™¯äº†ï¼
        canvas = st_canvas(
            fill_color="rgba(0, 255, 0, 1)",
            stroke_color="#00FF00",
            background_image=pil_img_resized, # ä½¿ç”¨ç¼©æ”¾åçš„å›¾åšèƒŒæ™¯
            update_streamlit=True,
            width=display_width,   # å¼ºåˆ¶å®½åº¦
            height=display_height, # å¼ºåˆ¶é«˜åº¦
            drawing_mode="point",
            point_display_radius=5,
            key="canvas_immersive"
        )
        
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç‚¹å‡»"):
            st.rerun()

    with col2:
        st.subheader("2. ç»“æœ")
        
        points = []
        if canvas.json_data and len(canvas.json_data["objects"]) > 0:
            for obj in canvas.json_data["objects"]:
                points.append([obj['left'], obj['top']])
        
        if len(points) > 0:
            params = {'radius': radius, 'threshold': threshold}
            
            with st.spinner("åˆ†æä¸­..."):
                buds, res_img, template, _ = run_multi_point_matching(img_gray, points, params)
            
            st.metric("âœ… è®¡æ•°", f"{len(buds)} ä¸ª")
            
            # æ˜¾ç¤ºåˆæˆæ¨¡æ¿
            st.write("å¹³å‡ç‰¹å¾:")
            st.image(template, width=80, clamp=True, channels='GRAY')
            
            # æ˜¾ç¤ºç»“æœ
            st.image(res_img, use_column_width=True, caption="çº¢æ¡†=AIæ‰¾åˆ°çš„ç›®æ ‡")
        else:
            st.info("ğŸ‘ˆ è¯·åœ¨å·¦å›¾ç›´æ¥ç‚¹å‡» Bud ä¸­å¿ƒã€‚")

else:
    st.info("è¯·ä¸Šä¼ å›¾ç‰‡ã€‚")
