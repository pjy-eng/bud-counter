import streamlit as st
import cv2
import numpy as np
from PIL import Image
import plotly.express as px
from streamlit_drawable_canvas import st_canvas

# ==========================================
# 0. å…¨å±€é…ç½®
# ==========================================
st.set_page_config(page_title="High-Accuracy Bud Counter", layout="wide")

if 'roi_coords' not in st.session_state:
    st.session_state['roi_coords'] = None

# ==========================================
# 1. æ ¸å¿ƒç®—æ³•ï¼šå¤šå°ºåº¦ + å¤šè§’åº¦ æ¨¡æ¿åŒ¹é…
# ==========================================
def rotate_image(image, angle):
    """è¾…åŠ©å‡½æ•°ï¼šæ—‹è½¬å›¾åƒ"""
    image_center = tuple(np.array(image.shape[1::-1]) / 2)
    rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)
    result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)
    return result

def process_multiscale_matching(img_gray, roi_coords, params):
    try:
        # --- A. é¢„å¤„ç† ---
        if img_gray.dtype != np.uint8:
            img_gray = img_gray.astype(np.uint8)

        # å¯¹æ¯”åº¦å¢å¼º (CLAHE)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        img_enhanced = clahe.apply(img_gray)
        
        # --- B. å‡†å¤‡æ¨¡æ¿ ---
        rx, ry, rw, rh = roi_coords['left'], roi_coords['top'], roi_coords['width'], roi_coords['height']
        h, w = img_enhanced.shape
        
        # è¾¹ç•Œæ£€æŸ¥
        if rw <= 5 or rh <= 5 or rx >= w or ry >= h:
            return None, None, "æ¡†é€‰åŒºåŸŸæ— æ•ˆæˆ–å¤ªå°ã€‚"
            
        base_template = img_enhanced[ry:ry+rh, rx:rx+rw]
        
        # --- C. å¤šå°ºåº¦ + å¤šè§’åº¦æœç´¢ ---
        all_detections = [] # å­˜å‚¨æ ¼å¼: [x, y, w, h, score]
        
        # 1. å®šä¹‰æœç´¢èŒƒå›´
        # å°ºåº¦ï¼šä» 0.8 å€åˆ° 1.2 å€ï¼Œåˆ† 5 æ¡£
        scales = np.linspace(0.8, 1.2, 5) 
        # è§’åº¦ï¼š0, 90, 180, 270 (å¦‚æœéœ€è¦æ›´ç²¾ç»†å¯ä»¥åŠ  45, 135...)
        angles = [0, 90, 180, 270] if params['use_rotation'] else [0]
        
        threshold = params['match_thresh']

        # 2. å¾ªç¯åŒ¹é… (æš´åŠ›æœç´¢)
        for scale in scales:
            # ç¼©æ”¾æ¨¡æ¿
            t_w = int(base_template.shape[1] * scale)
            t_h = int(base_template.shape[0] * scale)
            
            if t_w <= 0 or t_h <= 0 or t_w > w or t_h > h: continue
            
            scaled_template_base = cv2.resize(base_template, (t_w, t_h))
            
            for angle in angles:
                # æ—‹è½¬æ¨¡æ¿
                if angle == 0:
                    curr_template = scaled_template_base
                else:
                    curr_template = rotate_image(scaled_template_base, angle)

                # åŒ¹é…
                res = cv2.matchTemplate(img_enhanced, curr_template, cv2.TM_CCOEFF_NORMED)
                
                # ç­›é€‰
                loc = np.where(res >= threshold)
                for pt in zip(*loc[::-1]):
                    # è®°å½•ç»“æœï¼šx, y, w, h, score
                    score = res[pt[1], pt[0]]
                    all_detections.append([int(pt[0]), int(pt[1]), t_w, t_h, score])

        # --- D. NMS (éæå¤§å€¼æŠ‘åˆ¶) å»é‡ ---
        if not all_detections:
            return [], cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR), "æœªæ‰¾åˆ°åŒ¹é…ç›®æ ‡ï¼Œè¯·é™ä½é˜ˆå€¼ã€‚"

        # å°† list è½¬ä¸º numpy array ä»¥ä¾¿å¤„ç†
        detections = np.array(all_detections)
        
        # OpenCV çš„ groupRectangles éœ€è¦ [x, y, w, h] æ ¼å¼
        # ä½†æˆ‘ä»¬éœ€è¦ä¿ç•™ score æ¥åšæ›´é«˜çº§çš„ç­›é€‰ï¼Œè¿™é‡Œæ‰‹å†™ä¸€ä¸ªç®€å•çš„åŸºäº score çš„ NMS
        # æˆ–è€…ä¸ºäº†ç®€å•ç¨³å®šï¼Œä½¿ç”¨ OpenCV çš„ groupRectangles (ä¸è€ƒè™‘ scoreï¼Œåªè€ƒè™‘ä½ç½®)
        
        # è½¬æ¢æ ¼å¼é€‚é… cv2.groupRectangles
        rects_for_cv = []
        for det in detections:
            rects_for_cv.append([int(det[0]), int(det[1]), int(det[2]), int(det[3])])
        
        # groupThreshold=1: è‡³å°‘é‡å  1 æ¬¡ (å»å™ª)
        # eps=0.2: é‡å é˜ˆå€¼
        nms_rects, weights = cv2.groupRectangles(rects_for_cv, groupThreshold=1, eps=0.2)
        
        # --- E. ç»˜å›¾ä¸æ’é™¤è‡ªèº« ---
        res_img = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)
        final_buds = []
        
        user_center = (rx + rw//2, ry + rh//2)
        
        for (x, y, w_box, h_box) in nms_rects:
            # è®¡ç®—ä¸­å¿ƒè·ç¦»ï¼Œæ’é™¤ç”¨æˆ·è‡ªå·±ç”»çš„é‚£ä¸ªæ¡†
            curr_center = (x + w_box//2, y + h_box//2)
            dist = np.sqrt((user_center[0]-curr_center[0])**2 + (user_center[1]-curr_center[1])**2)
            
            if dist < rw / 2: # å¦‚æœéå¸¸æ¥è¿‘åŸç‚¹ï¼Œè·³è¿‡
                continue
                
            final_buds.append([x, y, w_box, h_box])
            
            # ç”»çº¢æ¡† (æ˜¾ç¤ºæ‰¾åˆ°çš„ç›®æ ‡)
            cv2.rectangle(res_img, (x, y), (x + w_box, y + h_box), (0, 0, 255), 2)

        # ç”»ç»¿æ¡† (ç”¨æˆ·æ¨¡æ¿)
        cv2.rectangle(res_img, (rx, ry), (rx+rw, ry+rh), (0, 255, 0), 2)
        
        return final_buds, res_img, f"æœç´¢å®Œæˆ"

    except Exception as e:
        return None, None, f"ç®—æ³•é”™è¯¯: {str(e)}"

# ==========================================
# 2. UI å¸ƒå±€
# ==========================================
st.sidebar.header("ğŸ›ï¸ é«˜çº§è®¾ç½®")

params = {
    'match_thresh': st.sidebar.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.3, 0.95, 0.60, 0.01, help="è¶Šä½è¶Šå®¹æ˜“æ‰¾åˆ°ï¼ˆå¯èƒ½è¯¯æŠ¥ï¼‰ï¼Œè¶Šé«˜è¶Šç²¾å‡†"),
    'use_rotation': st.sidebar.checkbox("å¯ç”¨æ—‹è½¬æœç´¢ (æ›´å‡†ä½†æ›´æ…¢)", value=False, help="å‹¾é€‰åä¼šå°è¯•ä¸åŒè§’åº¦åŒ¹é…ï¼Œè€—æ—¶å¢åŠ  4 å€")
}

st.title("ğŸ”¬ é«˜ç²¾åº¦ç»†èƒè®¡æ•° (å¤šå°ºåº¦ç‰ˆ)")
st.markdown("æ­¤ç‰ˆæœ¬ä¼šè‡ªåŠ¨æœç´¢ **å¤§å°ä¸åŒ (Â±20%)** çš„ç›®æ ‡ã€‚å‹¾é€‰å·¦ä¾§ **æ—‹è½¬æœç´¢** å¯è¿›ä¸€æ­¥æé«˜å‡†ç¡®ç‡ã€‚")

uploaded_file = st.file_uploader("1. ä¸Šä¼ å›¾åƒ", type=["jpg", "png", "tif"])

if uploaded_file:
    pil_img = Image.open(uploaded_file).convert("RGB")
    img_array = np.array(pil_img)
    img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("2. å®šä¹‰æ¨¡æ¿")
        st.caption("æ¡†é€‰ä¸€ä¸ªæ¸…æ™°çš„ Bud ä½œä¸ºåŸºå‡†ã€‚")
        canvas_result = st_canvas(
            fill_color="rgba(0, 255, 0, 0.2)",
            stroke_color="#00FF00",
            background_image=pil_img,
            update_streamlit=True,
            height=500,
            drawing_mode="rect",
            key="canvas_multi",
        )

    with col2:
        st.subheader("3. æ™ºèƒ½åˆ†æ")
        
        if canvas_result.json_data and len(canvas_result.json_data["objects"]) > 0:
            obj = canvas_result.json_data["objects"][-1]
            roi_coords = {
                'left': int(obj['left']), 'top': int(obj['top']),
                'width': int(obj['width']), 'height': int(obj['height'])
            }
            
            if roi_coords['width'] > 0:
                with st.spinner("æ­£åœ¨è¿›è¡Œå¤šå°ºåº¦å…¨å›¾æ‰«æ..."):
                    buds, res_img, msg = process_multiscale_matching(img_gray, roi_coords, params)

                if buds is not None:
                    count = len(buds) + 1
                    st.metric("âœ… æœ€ç»ˆè®¡æ•°", f"{count} ä¸ª")
                    
                    fig = px.imshow(res_img)
                    fig.update_layout(margin=dict(l=0, r=0, t=0, b=0), height=400)
                    st.plotly_chart(fig, use_container_width=True)
                    
                    st.success(f"å·²è‡ªåŠ¨åŒ¹é… 0.8x ~ 1.2x å¤§å°çš„ç›®æ ‡")
                else:
                    st.warning(msg)
        else:
            st.info("ğŸ‘ˆ è¯·å…ˆç”»æ¡†ã€‚")

else:
    st.info("è¯·ä¸Šä¼ å›¾ç‰‡ã€‚")
