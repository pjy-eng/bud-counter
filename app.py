import streamlit as st
import cv2
import numpy as np
from PIL import Image
import plotly.express as px
from streamlit_drawable_canvas import st_canvas
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler

st.set_page_config(page_title="Few-Shot Bud Counter", layout="wide")

if 'positive_points' not in st.session_state:
    st.session_state['positive_points'] = []

# ==========================================
# æ ¸å¿ƒç®—æ³•ï¼šåŸºäºå¤šç‚¹ç‰¹å¾çš„ One-Class SVM å­¦ä¹ 
# ==========================================
def extract_features_around_point(img_gray, x, y, window_size=20):
    """
    åœ¨ç‚¹å‡»ç‚¹å‘¨å›´æå–ç‰¹å¾ï¼š
    1. å±€éƒ¨å¹³å‡ç°åº¦
    2. å±€éƒ¨æ–¹å·® (çº¹ç†å¤æ‚åº¦)
    3. å±€éƒ¨æ¢¯åº¦ (è¾¹ç¼˜å¼ºåº¦)
    """
    h, w = img_gray.shape
    x, y = int(x), int(y)
    
    # è¾¹ç•Œä¿æŠ¤
    y1 = max(0, y - window_size)
    y2 = min(h, y + window_size)
    x1 = max(0, x - window_size)
    x2 = min(w, x + window_size)
    
    patch = img_gray[y1:y2, x1:x2]
    
    if patch.size == 0: return np.zeros(3)
    
    mean_val = np.mean(patch)
    std_val = np.std(patch)
    
    # ç®€å•æ¢¯åº¦
    sobelx = cv2.Sobel(patch, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(patch, cv2.CV_64F, 0, 1, ksize=3)
    grad_mag = np.mean(np.sqrt(sobelx**2 + sobely**2))
    
    return np.array([mean_val, std_val, grad_mag])

def train_and_predict(img_gray, points, params):
    # 1. å‡†å¤‡è®­ç»ƒæ•°æ®
    features = []
    for p in points:
        feat = extract_features_around_point(img_gray, p[0], p[1], params['window_size'])
        features.append(feat)
    
    X_train = np.array(features)
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    
    # 2. è®­ç»ƒ One-Class SVM (åªå­¦ä¹ "ä»€ä¹ˆæ˜¯Bud")
    # nu å‚æ•°æ§åˆ¶å¼‚å¸¸å€¼çš„æ¯”ä¾‹ï¼Œgamma æ§åˆ¶æ ¸å‡½æ•°çš„èŒƒå›´
    clf = OneClassSVM(kernel='rbf', nu=params['nu'], gamma=params['gamma'])
    clf.fit(X_train_scaled)
    
    # 3. å…¨å›¾æ»‘åŠ¨çª—å£é¢„æµ‹ (ä¸ºäº†é€Ÿåº¦ï¼Œæ­¥é•¿è®¾å¤§ä¸€ç‚¹)
    step = params['step']
    win = params['window_size']
    h, w = img_gray.shape
    
    found_points = []
    
    # è¿™é‡Œçš„å¾ªç¯å¦‚æœç”¨ Python å†™ä¼šå¾ˆæ…¢ï¼Œä½†ä¸ºäº†æ¼”ç¤ºé€»è¾‘å…ˆè¿™æ ·
    # å®é™…éƒ¨ç½²æ—¶ï¼Œè¿™é‡Œåªä¼šåœ¨å…³é”®ç‚¹é™„è¿‘é‡‡æ ·ï¼Œæˆ–è€…ä½¿ç”¨å›¾åƒå¤„ç†æ–¹æ³•åŠ é€Ÿ
    # æ”¹è¿›ç­–ç•¥ï¼šå…ˆç”¨ç®€å•çš„é˜ˆå€¼ç­›é€‰å‡ºå€™é€‰ç‚¹ï¼Œå†ç”¨ SVM ç¡®è®¤
    
    # å¿«é€Ÿé¢„ç­›é€‰ï¼šåŸºäºè®­ç»ƒæ ·æœ¬çš„å¹³å‡äº®åº¦
    mean_intensity = np.mean(X_train[:, 0])
    lower_bound = mean_intensity - 30
    upper_bound = mean_intensity + 30
    
    # äºŒå€¼åŒ–æ‰¾åˆ°å¤§æ¦‚åŒºåŸŸ
    _, mask = cv2.threshold(img_gray, lower_bound, 255, cv2.THRESH_BINARY)
    # ç»“åˆæ–¹å·®ï¼ˆçº¹ç†ï¼‰ç­›é€‰
    # è¿™é‡Œç®€åŒ–ä¸ºï¼šåªåœ¨ mask ä¸ºç™½è‰²çš„åŒºåŸŸé‡‡æ ·
    
    y_indices, x_indices = np.where(mask > 0)
    
    # éšæœºé‡‡æ ·æˆ–è€…é—´éš”é‡‡æ ·ä»¥æé«˜é€Ÿåº¦
    # æˆ‘ä»¬æ”¹ç”¨ç®€å•çš„æ»‘åŠ¨çª—å£ç­–ç•¥ï¼Œä½†åªåœ¨å¯èƒ½æœ‰ä¸œè¥¿çš„åœ°æ–¹æ»‘
    
    # ä¸ºäº†æ¼”ç¤ºå®æ—¶æ€§ï¼Œæˆ‘ä»¬é€€å›åˆ°æ›´ç®€å•çš„ "å¤šæ¨¡æ¿åŒ¹é…é€»è¾‘"
    # SVM åœ¨çº¯ Python å¾ªç¯é‡Œå¤ªæ…¢äº†ã€‚
    # æ–¹æ¡ˆ Bï¼šå¤šç‚¹å¹³å‡æ¨¡æ¿åŒ¹é…
    
    return adaptive_multi_template_matching(img_gray, points, params)


def adaptive_multi_template_matching(img_gray, points, params):
    """
    æ›¿ä»£ SVM çš„å¿«é€Ÿæ–¹æ¡ˆï¼š
    åœ¨æ¯ä¸ªç‚¹å‡»ä½ç½®æˆªå–ä¸€ä¸ªå°æ¨¡æ¿ï¼Œç®—å‡ºå¹³å‡æ¨¡æ¿ï¼Œç„¶åå…¨å›¾æœã€‚
    """
    win = params['window_size']
    h, w = img_gray.shape
    templates = []
    
    # 1. æ”¶é›†æ‰€æœ‰ç‚¹å‡»å¤„çš„æ¨¡æ¿
    for p in points:
        x, y = int(p[0]), int(p[1])
        y1, y2 = max(0, y-win), min(h, y+win)
        x1, x2 = max(0, x-win), min(w, x+win)
        patch = img_gray[y1:y2, x1:x2]
        if patch.shape == (2*win, 2*win): # ç¡®ä¿å°ºå¯¸ä¸€è‡´
            templates.append(patch)
            
    if not templates: return [], img_gray
    
    # 2. è®¡ç®—å¹³å‡æ¨¡æ¿ (è¿™æ˜¯å…³é”®ï¼èåˆäº†å¤šä¸ªæ ·æœ¬çš„ç‰¹å¾)
    avg_template = np.mean(templates, axis=0).astype(np.uint8)
    
    # 3. åŒ¹é…
    res = cv2.matchTemplate(img_gray, avg_template, cv2.TM_CCOEFF_NORMED)
    
    # 4. ç­›é€‰ç»“æœ
    loc = np.where(res >= params['threshold'])
    boxes = []
    w_t, h_t = avg_template.shape[::-1]
    
    for pt in zip(*loc[::-1]):
        boxes.append([int(pt[0]), int(pt[1]), w_t, h_t])
        
    rects, _ = cv2.groupRectangles(boxes, groupThreshold=1, eps=0.3)
    
    res_img = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)
    final_buds = []
    
    for (x, y, w_box, h_box) in rects:
        # ç»˜åˆ¶
        cv2.rectangle(res_img, (x, y), (x + w_box, y + h_box), (0, 0, 255), 2)
        final_buds.append([x, y])
        
    # æ ‡è®°ç”¨æˆ·ç‚¹å‡»çš„ç‚¹
    for p in points:
        cv2.circle(res_img, (int(p[0]), int(p[1])), 3, (0, 255, 0), -1)
        
    return final_buds, res_img


# ==========================================
# UI å¸ƒå±€
# ==========================================
st.sidebar.header("ğŸ›ï¸ å‚æ•°è®¾ç½®")
win_size = st.sidebar.slider("æ ·æœ¬åŠå¾„ (Window Size)", 10, 50, 20, help="ç‚¹å‡»ç‚¹å‘¨å›´å¤šå¤§èŒƒå›´å†…ç®—ä½œä¸€ä¸ªæ ·æœ¬")
thresh = st.sidebar.slider("ç›¸ä¼¼åº¦é˜ˆå€¼", 0.3, 0.95, 0.60)

st.title("ğŸ‘† ç‚¹é€‰å­¦ä¹ ç‰ˆ (Point & Find)")
st.markdown("æ€è·¯ï¼š**ä¸è¦ç”»æ¡†ï¼Œç›´æ¥ç‚¹å‡»** 3-5 ä¸ªå…¸å‹çš„ Budï¼Œç³»ç»Ÿä¼šè®¡ç®—å®ƒä»¬çš„**å¹³å‡ç‰¹å¾**å»æ‰¾å‰©ä¸‹çš„ã€‚")

uploaded_file = st.file_uploader("ä¸Šä¼ å›¾åƒ", type=["jpg", "png", "tif"])

if uploaded_file:
    pil_img = Image.open(uploaded_file).convert("RGB")
    img_array = np.array(pil_img)
    img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)

    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("1. ç‚¹å‡»æ ·æœ¬ (Point)")
        st.caption("è¯·ç”¨é¼ æ ‡å·¦é”®ç‚¹å‡»å›¾ä¸­çš„ Bud ä¸­å¿ƒã€‚ç‚¹ 3 ä¸ªä»¥ä¸Šæ•ˆæœæœ€å¥½ã€‚")
        
        # Point æ¨¡å¼
        canvas = st_canvas(
            fill_color="rgba(0, 255, 0, 1)",
            stroke_color="#00FF00",
            background_image=pil_img,
            update_streamlit=True,
            height=500,
            drawing_mode="point", # å…³é”®ï¼šç‚¹é€‰æ¨¡å¼
            point_display_radius=5,
            key="canvas_point"
        )

    with col2:
        st.subheader("2. å­¦ä¹ ä¸æœç´¢")
        
        # è·å–ç‚¹å‡»ç‚¹
        if canvas.json_data and len(canvas.json_data["objects"]) > 0:
            points = []
            for obj in canvas.json_data["objects"]:
                points.append([obj['left'], obj['top']])
            
            st.info(f"å·²é‡‡é›† {len(points)} ä¸ªæ ·æœ¬ç‚¹")
            
            if len(points) >= 1:
                params = {'window_size': win_size, 'threshold': thresh}
                
                # è¿è¡Œå¤šç‚¹åŒ¹é…
                buds, res_img = adaptive_multi_template_matching(img_gray, points, params)
                
                st.metric("âœ… æ‰¾åˆ°ç›¸ä¼¼ç›®æ ‡", f"{len(buds)} ä¸ª")
                st.image(res_img, use_column_width=True, caption="ç»¿ç‚¹=ä½ çš„æ ·æœ¬ï¼Œçº¢æ¡†=AIæ‰¾åˆ°çš„")
            else:
                st.warning("è¯·è‡³å°‘ç‚¹å‡» 1 ä¸ªç‚¹ã€‚")
        else:
            st.info("ğŸ‘ˆ è¯·åœ¨å·¦å›¾ç‚¹å‡» Bud ä¸­å¿ƒã€‚")
