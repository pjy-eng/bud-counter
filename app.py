import streamlit as st
import cv2
import numpy as np
from PIL import Image
import plotly.express as px
import plotly.graph_objects as go

# ==========================================
# 0. å…¨å±€é…ç½®ä¸çŠ¶æ€åˆå§‹åŒ–
# ==========================================
st.set_page_config(page_title="Template-Guided Bud Counter", layout="wide")

# åˆå§‹åŒ– Session State ç”¨äºå­˜å‚¨ ROI å’Œ å¤„ç†çŠ¶æ€
if 'roi_coords' not in st.session_state:
    st.session_state['roi_coords'] = None  # æ ¼å¼: {'x':, 'y':, 'w':, 'h':}
if 'processed_result' not in st.session_state:
    st.session_state['processed_result'] = None

# ==========================================
# 1. æ ¸å¿ƒç®—æ³•åº“ (ç‰¹å¾æå– + åŒ¹é…)
# ==========================================

def get_contour_features(contour, img_gray_roi=None):
    """
    è®¡ç®—è½®å»“çš„å‡ ä½•ç‰¹å¾ï¼šé¢ç§¯ã€å‘¨é•¿ã€åœ†åº¦ã€å¹³å‡ç°åº¦(å¯é€‰)
    """
    area = cv2.contourArea(contour)
    perimeter = cv2.arcLength(contour, True)
    
    # åœ†åº¦è®¡ç®—: 4 * pi * area / perimeter^2 (å®Œç¾åœ†=1.0)
    if perimeter == 0:
        circularity = 0
    else:
        circularity = (4 * np.pi * area) / (perimeter ** 2)
    
    mean_val = 0
    if img_gray_roi is not None:
        mask = np.zeros(img_gray_roi.shape, dtype=np.uint8)
        cv2.drawContours(mask, [contour], -1, 255, -1)
        mean_val = cv2.mean(img_gray_roi, mask=mask)[0]

    return {
        "area": area,
        "circularity": circularity,
        "mean_val": mean_val,
        "contour": contour
    }

def watershed_segmentation_candidates(img_gray):
    """
    ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆå…¨å›¾å€™é€‰åŒºåŸŸ (Candidate Generation)
    ä½¿ç”¨ è·ç¦»å˜æ¢ + åˆ†æ°´å²­ ç®—æ³•ï¼Œå°½å¯èƒ½æŠŠç²˜è¿çš„ç»†èƒåˆ†å¼€
    """
    # 1. é¢„å¤„ç†
    # CLAHE å¢å¼ºå¯¹æ¯”åº¦
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(img_gray)
    # é«˜æ–¯æ¨¡ç³Šå»å™ª
    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)

    # 2. äºŒå€¼åŒ– (Otsu)
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # 3. å½¢æ€å­¦å»å™ª (å¼€è¿ç®—)
    kernel = np.ones((3, 3), np.uint8)
    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)

    # 4. è·ç¦»å˜æ¢å¯»æ‰¾ç¡®å®šçš„å‰æ™¯ (Sure Foreground)
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, 0.5 * dist_transform.max(), 255, 0) # 0.5 æ˜¯è·ç¦»é˜ˆå€¼ï¼Œå¯è°ƒ
    sure_fg = np.uint8(sure_fg)

    # 5. ç¡®å®šçš„èƒŒæ™¯ (Sure Background)
    sure_bg = cv2.dilate(opening, kernel, iterations=3)

    # 6. æœªçŸ¥åŒºåŸŸ (Unknown)
    unknown = cv2.subtract(sure_bg, sure_fg)

    # 7. åˆ†æ°´å²­æ ‡è®°
    _, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0

    img_color = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)
    markers = cv2.watershed(img_color, markers)

    # 8. æå–æ‰€æœ‰å€™é€‰è½®å»“
    candidates = []
    # label 0 æ˜¯è¾¹ç•Œ, 1 æ˜¯èƒŒæ™¯, >1 æ˜¯ç‰©ä½“
    unique_labels = np.unique(markers)
    for label in unique_labels:
        if label <= 1: 
            continue
        
        # åˆ›å»ºå½“å‰ label çš„æ©ç 
        mask = np.zeros(img_gray.shape, dtype=np.uint8)
        mask[markers == label] = 255
        
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if cnts:
            # å–è¯¥ label åŒºåŸŸæœ€å¤§çš„è½®å»“
            c = max(cnts, key=cv2.contourArea)
            candidates.append(c)
            
    return candidates

def template_guided_detection(img_gray, roi_coords):
    """
    ç¬¬äºŒæ­¥ï¼šåŸºäºæ¨¡æ¿ç‰¹å¾ç­›é€‰ (Feature Matching)
    """
    # 1. è§£æ ROI å¹¶æå–æ¨¡æ¿ç‰¹å¾
    rx, ry, rw, rh = roi_coords['x'], roi_coords['y'], roi_coords['w'], roi_coords['h']
    
    # ç¡®ä¿ ROI åœ¨å›¾åƒèŒƒå›´å†…
    h, w = img_gray.shape
    rx, ry = max(0, rx), max(0, ry)
    rw, rh = min(w - rx, rw), min(h - ry, rh)
    
    roi_img = img_gray[ry:ry+rh, rx:rx+rw]
    
    # å¯¹ ROI åšç®€å•çš„ Otsu è·å–ä¸»è¦è½®å»“ç‰¹å¾
    _, roi_thresh = cv2.threshold(roi_img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    roi_cnts, _ = cv2.findContours(roi_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not roi_cnts:
        return None, "ROI ä¸­æœªæ£€æµ‹åˆ°æœ‰æ•ˆç›®æ ‡ï¼Œè¯·é‡æ–°æ¡†é€‰"
        
    template_cnt = max(roi_cnts, key=cv2.contourArea)
    tmpl_feats = get_contour_features(template_cnt, roi_img)
    
    # 2. è·å–å…¨å›¾å€™é€‰åˆ—è¡¨
    candidates = watershed_segmentation_candidates(img_gray)
    
    # 3. ç­›é€‰é€»è¾‘ (Matching Logic)
    final_buds = []
    
    # è®¾å®šå®¹å·® (Tolerance)
    area_tol = 0.50      # é¢ç§¯å…è®¸ Â±50% å·®å¼‚
    circ_threshold = 0.6 # åœ†åº¦è‡³å°‘å¤§äº 0.6 (é˜²æ­¢é•¿æ¡å½¢å™ªå£°)
    
    for cnt in candidates:
        cand_feats = get_contour_features(cnt) # è¿™é‡Œä¸ºäº†é€Ÿåº¦æš‚æ—¶ä¸ä¼  img_gray ç®—ç°åº¦ï¼Œåªç”¨å‡ ä½•ç‰¹å¾
        
        # A. é¢ç§¯ç­›é€‰
        area_diff = abs(cand_feats['area'] - tmpl_feats['area']) / tmpl_feats['area']
        if area_diff > area_tol:
            continue
            
        # B. åœ†åº¦ç­›é€‰ (Bud åº”è¯¥æ˜¯åœ†çš„)
        if cand_feats['circularity'] < circ_threshold:
            continue
            
        final_buds.append(cnt)
        
    return final_buds, tmpl_feats

# ==========================================
# 2. è¾…åŠ©åŠŸèƒ½ï¼šPlotly ROI è§£æä¸ç»˜åˆ¶
# ==========================================

def parse_plotly_relayout(relayout_data):
    """è§£æ Plotly ä¼ å›çš„æ¡†é€‰æ•°æ®ï¼Œåªå–æœ€åä¸€ä¸ªæ¡†"""
    if not relayout_data:
        return None
    
    # å¤„ç† 'shapes[0].x0' è¿™ç§æ‰å¹³ç»“æ„
    if "shapes[0].x0" in relayout_data:
        x0 = relayout_data["shapes[0].x0"]
        x1 = relayout_data["shapes[0].x1"]
        y0 = relayout_data["shapes[0].y0"]
        y1 = relayout_data["shapes[0].y1"]
    # å¤„ç† 'shapes': [{'x0':...}] è¿™ç§åµŒå¥—ç»“æ„
    elif "shapes" in relayout_data and len(relayout_data["shapes"]) > 0:
        last_shape = relayout_data["shapes"][-1]
        x0, x1 = last_shape["x0"], last_shape["x1"]
        y0, y1 = last_shape["y0"], last_shape["y1"]
    else:
        return None

    return {
        "x": int(min(x0, x1)),
        "y": int(min(y0, y1)),
        "w": int(abs(x1 - x0)),
        "h": int(abs(y1 - y0))
    }

def reset_callback():
    """æ’¤é”€ ROI çš„å›è°ƒ"""
    st.session_state['roi_coords'] = None
    st.session_state['processed_result'] = None

# ==========================================
# 3. Streamlit UI ä¸»é€»è¾‘
# ==========================================

st.title("ğŸ”¬ æ™ºèƒ½ç»†èƒè®¡æ•°ç³»ç»Ÿ (å·¥ç¨‹é‡æ„ç‰ˆ)")
st.markdown("""
<style>
    .big-font { font-size:18px !important; }
    .result-box { border: 2px solid #ddd; padding: 15px; border-radius: 10px; }
</style>
æ­¤ç‰ˆæœ¬é‡‡ç”¨ **ROI æ¨¡æ¿é©±åŠ¨ (Template-Guided)** ç®—æ³•ã€‚
1. ä¸Šä¼ å›¾ç‰‡ -> 2. åœ¨å›¾ä¸Šæ¡†é€‰**ä¸€ä¸ªæ ‡å‡† Bud** -> 3. ç®—æ³•è‡ªåŠ¨å¯»æ‰¾ç›¸ä¼¼ç›®æ ‡ã€‚
""", unsafe_allow_html=True)

uploaded_file = st.file_uploader("ğŸ“‚ ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ˜¾å¾®å›¾åƒ", type=["png", "jpg", "tif"])

if uploaded_file:
    # åŠ è½½å›¾ç‰‡
    pil_img = Image.open(uploaded_file).convert("RGB")
    img_array = np.array(pil_img)
    img_gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    
    h, w, _ = img_array.shape
    
    # --- äº¤äº’åŒºåŸŸ ---
    st.divider()
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ–±ï¸ ç¬¬äºŒæ­¥ï¼šæ¡†é€‰æ¨¡æ¿ (ROI)")
        
        # åˆ›å»º Plotly å›¾å½¢
        fig = px.imshow(pil_img)
        fig.update_layout(
            dragmode='drawrect', # æ¿€æ´»ç”»çŸ©å½¢æ¨¡å¼
            newshape=dict(line_color='cyan', line_width=3),
            margin=dict(l=0, r=0, t=0, b=0),
            height=500
        )
        
        # å¦‚æœ Session ä¸­å·²ç»æœ‰ ROIï¼ŒæŠŠå®ƒç”»å‡ºæ¥ (æŒä¹…åŒ–æ˜¾ç¤º)
        if st.session_state['roi_coords']:
            rc = st.session_state['roi_coords']
            fig.add_shape(
                type="rect",
                x0=rc['x'], y0=rc['y'], x1=rc['x']+rc['w'], y1=rc['y']+rc['h'],
                line=dict(color="green", width=4),
            )
            fig.update_layout(title=dict(text="âœ… å·²é”å®š ROI (å¦‚éœ€é‡ç”»è¯·ç‚¹å‡»ä¸‹æ–¹æ’¤é”€)", font=dict(color="green")))

        # æ¸²æŸ“ Plotly
        # key ä¿æŒä¸å˜ï¼Œé€šè¿‡ session state ç®¡ç†æ•°æ®
        relayout_data = st.plotly_chart(fig, use_container_width=True, on_select="ignore") 
        
        # --- çŠ¶æ€æ›´æ–°é€»è¾‘ ---
        # åªæœ‰å½“ç”¨æˆ·çœŸçš„ç”»äº†æ–°æ¡†æ—¶ï¼Œæ‰æ›´æ–° session_state
        # æ³¨æ„ï¼šStreamlit çš„ st.plotly_chart è¿”å›å€¼æ¯”è¾ƒ trickyï¼Œéœ€è¦åˆ¤æ–­ keys
        if relayout_data and ("shapes" in relayout_data or "shapes[0].x0" in relayout_data):
            new_roi = parse_plotly_relayout(relayout_data)
            if new_roi:
                st.session_state['roi_coords'] = new_roi
                st.rerun() # å¼ºåˆ¶åˆ·æ–°ä»¥é”å®šç»¿æ¡†

    with col2:
        st.subheader("âš™ï¸ æ“ä½œé¢æ¿")
        
        # æ’¤é”€æŒ‰é’®
        if st.session_state['roi_coords']:
            st.info(f"å½“å‰æ¨¡æ¿åŒºåŸŸ: \nX: {st.session_state['roi_coords']['x']}, Y: {st.session_state['roi_coords']['y']}")
            st.button("ğŸ”„ æ’¤é”€ / é‡ç”» ROI", on_click=reset_callback, type="primary")
            
            st.divider()
            
            # å¼€å§‹è¯†åˆ«æŒ‰é’®
            if st.button("ğŸš€ å¼€å§‹è¯†åˆ«åˆ†æ"):
                with st.spinner("æ­£åœ¨è¿›è¡Œç‰¹å¾æå–ä¸å…¨å›¾åŒ¹é…..."):
                    buds, template_features = template_guided_detection(img_gray, st.session_state['roi_coords'])
                    
                    if template_features and isinstance(template_features, dict):
                        # ç»˜åˆ¶ç»“æœå›¾
                        res_img = img_array.copy()
                        
                        # 1. ç”» ROI (ç»¿è‰²)
                        rx, ry, rw, rh = st.session_state['roi_coords']['x'], st.session_state['roi_coords']['y'], st.session_state['roi_coords']['w'], st.session_state['roi_coords']['h']
                        cv2.rectangle(res_img, (rx, ry), (rx+rw, ry+rh), (0, 255, 0), 2)
                        
                        # 2. ç”»è¯†åˆ«åˆ°çš„ Buds (çº¢è‰²ç»†çº¿) + è´¨å¿ƒ (é»„è‰²ç‚¹)
                        for cnt in buds:
                            # è½®å»“
                            cv2.drawContours(res_img, [cnt], -1, (255, 0, 0), 2) 
                            # è´¨å¿ƒ
                            M = cv2.moments(cnt)
                            if M["m00"] != 0:
                                cX = int(M["m10"] / M["m00"])
                                cY = int(M["m01"] / M["m00"])
                                cv2.circle(res_img, (cX, cY), 3, (255, 255, 0), -1)

                        # ä¿å­˜ç»“æœåˆ° Session
                        st.session_state['processed_result'] = {
                            'image': res_img,
                            'count': len(buds),
                            'template_area': template_features['area']
                        }
                    else:
                        st.error(template_features) # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯

        else:
            st.warning("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦å›¾æ¡†é€‰ä¸€ä¸ªæ ‡å‡† Bud")

    # --- ç»“æœå±•ç¤ºåŒº ---
    if st.session_state['processed_result']:
        st.divider()
        st.subheader("ğŸ“Š åˆ†æç»“æœ")
        
        res_data = st.session_state['processed_result']
        
        # æ˜¾ç¤ºç»Ÿè®¡æŒ‡æ ‡
        m1, m2 = st.columns(2)
        m1.metric("è¯†åˆ«æ€»æ•° (Count)", f"{res_data['count']} ä¸ª")
        m2.metric("æ¨¡æ¿åŸºå‡†é¢ç§¯", f"{int(res_data['template_area'])} pxÂ²")
        
        # æ˜¾ç¤ºç»“æœå¤§å›¾
        # é™åˆ¶æ˜¾ç¤ºå®½åº¦ï¼Œä¼˜åŒ–è§‚æ„Ÿ
        st.image(
            res_data['image'], 
            caption=f"è¯†åˆ«ç»“æœ visualization (Count: {res_data['count']}) - é»„ç‚¹ä¸ºè´¨å¿ƒï¼Œçº¢çº¿ä¸ºè½®å»“", 
            width=800  # é™åˆ¶æœ€å¤§æ˜¾ç¤ºå®½åº¦
        )

else:
    st.info("ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ã€‚è¯·ä¸Šä¼ å›¾ç‰‡å¼€å§‹ã€‚")
